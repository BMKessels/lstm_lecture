{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final LSTM_language_translation_19012020.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CK3qDmsgZbl8"
      },
      "source": [
        "# Pipple LSTM Language Translator Introduction\n",
        "\n",
        "This notebook runs you through all basic steps when building a machine learning language translator, using LSTM networks. The notebook is configured to be used in Google Colaboratory: a free of use Jupyter Notebook environment running on Google servers.\n",
        "\n",
        "Notebooks are documents which contain both computer code (e.g. python) and rich text elements (paragraph, equations, figures, links, etc…). Notebooks are both human-readable documents containing the analysis description and the results (figures, tables, etc..) as well as executable commands which can be run to perform data analysis. Google Colaboratory combines these features with other Google services such as Google Drive. \n",
        "\n",
        "Before continuing this tutorial make sure you select 'GPU' as hardware accelerator. This will speed up the time of training a the language translator model substantially. \n",
        "\n",
        "Runtime -> Change runtime type -> Hardware accelerator = 'GPU' -> Save\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6DQsbvz4sqD"
      },
      "source": [
        "# Table of Contents\n",
        "\n",
        "\n",
        "1.   Use case\n",
        "2.   Retrieve data\n",
        "3.   Data preparation\n",
        "4.   Sequence-to-sequence models\n",
        "5.   LSTM inputs\n",
        "6.   Creating a train and test set\n",
        "7.   Building the sequence-to-sequence model\n",
        "8.   Trainng the sequence-to-sequence model\n",
        "9.   Inferencing from the model\n",
        "10.  Improvements on the current architecture\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTOY5No8jvB"
      },
      "source": [
        "---\n",
        "---\n",
        "# 1. Use case\n",
        "\n",
        "\n",
        "In this tutorial you will be building your own LSTM language translator! Neural machine translation (NMT) is one of the many use cases the LSTM networks offer. Specifically, we will be introducing sequence-to-sequence models, using an encoder and decoder framework with LSTM as main block. The encoder-decoder architecture is currenty the state of the art in machine translation. Google Translate started using these kinds of models in production in late 2016, and the world happily translated ever after. \n",
        "\n",
        "We will train our LSTM language translator to translate English to Dutch:)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbwBbO7LGOIT"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "---\n",
        "\n",
        "# 2. Retrieve Data\n",
        "\n",
        "The data we use comes from sentences from the Taboeba Project (http://www.manythings.org/anki/) and can be retrieved by running the cell block below.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bkYxvqyMZZT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e80d3e3-c90d-47a5-e47b-e928a10a5abf"
      },
      "source": [
        "# clone github repository\n",
        "!git clone https://github.com/PippleNL/lstm_lecture.git\n",
        "\n",
        "\n",
        "# import packages\n",
        "import zipfile\n",
        "from os.path import join\n",
        "\n",
        "\n",
        "dataset = 'nld-eng'\n",
        "\n",
        "# path to zip\n",
        "local_zip = f'lstm_lecture/{dataset}.zip' \n",
        "\n",
        "# extract zip file\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall(f'/tmp/{dataset}')\n",
        "zip_ref.close()\n",
        "\n",
        "# data directory\n",
        "base_dir = '/tmp/'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'lstm_lecture'...\n",
            "remote: Enumerating objects: 6, done.\u001b[K\n",
            "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 6 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (6/6), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pKaw6_jSito"
      },
      "source": [
        "The data set is located at /tmp/nld-eng/nld.txt.\r\n",
        "\r\n",
        "Below are some bash commands listed to guide you through the repository and let you get a feeling of how the data set is structured."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6__VAtjQM_0Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f611730-33ec-46dc-9f65-450c21a6cb70"
      },
      "source": [
        "# list all files and directories in temp directory\n",
        "!ls '/tmp'"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dap_multiplexer.445384d9b81d.root.log.INFO.20210120-145735.51\n",
            "dap_multiplexer.INFO\n",
            "debugger_afkmqbzwz\n",
            "initgoogle_syslog_dir.0\n",
            "nld-eng\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vE01TvcgQz96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1845a200-6ecc-46f0-cde8-c2fef554ac1c"
      },
      "source": [
        "# list all files nld-eng folder.\n",
        "!ls '/tmp/nld-eng'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_about.txt  nld.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yhS7Pbj7Tbq2"
      },
      "source": [
        "Run the cell block below to get an impression of how the data looks like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "WriFGwsYTe0J",
        "outputId": "1fe95dcf-b52a-4a33-c7cf-c5fde7207eb9"
      },
      "source": [
        "# import packages\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "\r\n",
        "# translation settings\r\n",
        "translation = 'nld-eng'\r\n",
        "\r\n",
        "# data directory and text file path\r\n",
        "data_dir = join(base_dir, translation)\r\n",
        "inf_path = join(data_dir, f\"{translation.split('-')[0]}.txt\")\r\n",
        "\r\n",
        "# show data source\r\n",
        "df = pd.read_table(inf_path, names =['source', 'target', 'comments'])\r\n",
        "df.sample(5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>49859</th>\n",
              "      <td>I will have my sister pick you up at the station.</td>\n",
              "      <td>Ik zal mijn zus je laten oppikken aan het stat...</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9726</th>\n",
              "      <td>He finally arrived.</td>\n",
              "      <td>Hij is uiteindelijk aangekomen.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13934</th>\n",
              "      <td>Have you tried sushi?</td>\n",
              "      <td>Heb je sushi geprobeerd?</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17122</th>\n",
              "      <td>Raise your right hand.</td>\n",
              "      <td>Steek uw rechterhand op.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37432</th>\n",
              "      <td>I don't know where my gloves are.</td>\n",
              "      <td>Ik weet niet waar mijn handschoenen zijn.</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #7...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  source  ...                                           comments\n",
              "49859  I will have my sister pick you up at the station.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #3...\n",
              "9726                                 He finally arrived.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "13934                              Have you tried sushi?  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #4...\n",
              "17122                             Raise your right hand.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "37432                  I don't know where my gloves are.  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #7...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOPsuz3rTtHP"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 3. Data preparation\r\n",
        "\r\n",
        "Data preparation is an essential step in any machine learning tasks. For this use case, we do the following for both the source and target sentences:\r\n",
        "\r\n",
        "- Convert text to lower case\r\n",
        "- Remove quotes\r\n",
        "- Remove all special characters like @, !, *, &, ect\r\n",
        "- Remove digits from the sentences\r\n",
        "- Remove extra with spaces\r\n",
        "\r\n",
        "Next to that we add a START_ and _END token to the target sentences as this is very useful for training and inference purposes. These tags help in knowing when to start and end a translation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "VnHqGaRVU6vk",
        "outputId": "7f82fb66-72d7-4461-b9d1-076e9f919268"
      },
      "source": [
        "# import packages\r\n",
        "import re\r\n",
        "from string import punctuation, digits\r\n",
        "\r\n",
        "\r\n",
        "def data_prep(prep_series: pd.Series):\r\n",
        "  \"\"\"\r\n",
        "  Data preparation\r\n",
        "  :param prep_series: Pandas Series object\r\n",
        "  :return: Pandas Series object\r\n",
        "  \"\"\"\r\n",
        "  # convert to lower case\r\n",
        "  prep_series = prep_series.apply(lambda x: x.lower())\r\n",
        "\r\n",
        "  # remove quotes\r\n",
        "  prep_series = prep_series.apply(lambda x: re.sub(\"'\", '', x))\r\n",
        "\r\n",
        "  # remove special characters\r\n",
        "  prep_series = prep_series.apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\r\n",
        "\r\n",
        "  # remove digits\r\n",
        "  num_digits = str.maketrans('', '', digits)\r\n",
        "  prep_series = prep_series.apply(lambda x: x.translate(num_digits))\r\n",
        "  \r\n",
        "  # remove extra spaces\r\n",
        "  prep_series = prep_series.apply(lambda x: x.strip())\r\n",
        "  prep_series = prep_series.apply(lambda x: re.sub(\" +\", \" \", x))\r\n",
        "\r\n",
        "  if prep_series.name == 'target':\r\n",
        "    # add start and end tokens\r\n",
        "    prep_series = prep_series.apply(lambda x: 'START_ ' + x + ' _END')\r\n",
        "\r\n",
        "  return prep_series\r\n",
        "\r\n",
        "# prepate source and target sentences\r\n",
        "df.source = data_prep(df.source)\r\n",
        "df.target = data_prep(df.target)\r\n",
        "df.sample(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>comments</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>42366</th>\n",
              "      <td>how many books do you read per month</td>\n",
              "      <td>START_ hoeveel boeken leest ge per maand _END</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1523</th>\n",
              "      <td>tom is poor</td>\n",
              "      <td>START_ tom is arm _END</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25177</th>\n",
              "      <td>im glad to see you again</td>\n",
              "      <td>START_ ik ben blij jullie weer te zien _END</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1050</th>\n",
              "      <td>be merciful</td>\n",
              "      <td>START_ wees genadig _END</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34086</th>\n",
              "      <td>he gets a haircut once a month</td>\n",
              "      <td>START_ hij knipt zijn haar eens per maand _END</td>\n",
              "      <td>CC-BY 2.0 (France) Attribution: tatoeba.org #1...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     source  ...                                           comments\n",
              "42366  how many books do you read per month  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "1523                            tom is poor  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "25177              im glad to see you again  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "1050                            be merciful  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #2...\n",
              "34086        he gets a haircut once a month  ...  CC-BY 2.0 (France) Attribution: tatoeba.org #1...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brYR0GkyDkKo"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 4. Sequence-to-sequence models\r\n",
        "\r\n",
        "Sequence to sequence models map a source sequence to a target sequence, both text sentences in this use case. The source sequence is input language to the machine translation system, the target sequence is the output language."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "EXQblEWlC_Dl",
        "outputId": "95f96a71-81ae-4c32-ef9c-a495e7a3ee8a"
      },
      "source": [
        "from IPython.display import HTML\r\n",
        "HTML(\"\"\"\r\n",
        "    <video alt=\"s2s\" controls>\r\n",
        "        <source src=\"https://jalammar.github.io/images/seq2seq_4.mp4\" type=\"video/mp4\">\r\n",
        "    </video>\r\n",
        "\"\"\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "    <video alt=\"s2s\" controls>\n",
              "        <source src=\"https://jalammar.github.io/images/seq2seq_4.mp4\" type=\"video/mp4\">\n",
              "    </video>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDwRprL7C4Ei"
      },
      "source": [
        "Under the hood, the model is composed of an encoder and a decoder.\r\n",
        "The encoder processes each item in the input sequence and compiles the information it captures into a vector (called the context). After processing the entire input sequence, the encoder sends the context over to the decoder, which begins producing the output sequence item by item.\r\n",
        "\r\n",
        "The context is a vector (an array of numbers, basically) in the case of machine translation. The encoder and decoder tend to both be RNNs or likewise, such as LSTM networks. The vector represents the cell state (long-term memory) and the hidden state (working memory), in case of an LSTM, capturing the meaning of the sentence in a universal language (consisting of numbers).\r\n",
        "\r\n",
        "![context](https://jalammar.github.io/images/context.png)\r\n",
        "\r\n",
        "You can set the size of the context vector when you set up your model. It is basically the number of hidden units in the encoder LSTM. These visualizations show a vector of size 4, but in real world applications the context vector would be of a size like 256, 512, or 1024.\r\n",
        "\r\n",
        "For a simple and clear introduction to RNNs, please watch the video of Luis Serrano:) https://www.youtube.com/watch?v=UNmqTiOnRfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCbTemp0K7R4"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 5. LSTM inputs\r\n",
        "\r\n",
        "By design, a LSTM takes three inputs at each time step: an input (in the case of the encoder, one word from the input sentence), and a hidden state and a cell state. The word, however, needs to be represented by a vector. \r\n",
        "\r\n",
        "![embedding](https://jalammar.github.io/images/embedding.png)\r\n",
        "\r\n",
        "To transform a word into a vector, we turn to the class of methods called “word embedding” algorithms. These algorithms turn words into vector spaces that capture a lot of the meaning/semantic information of the words. One of the most famous embedding algorithms is word2vec, developed by Google.  \r\n",
        "\r\n",
        "![word2vec](https://miro.medium.com/max/3010/1*OEmWDt4eztOcm5pr2QbxfA.png)\r\n",
        "\r\n",
        "More information on embedding algorithms can be found on: https://machinelearningmastery.com/what-are-word-embeddings/\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "In keras, we illustrate this as follows:\r\n",
        "\r\n",
        "![input_keras](https://miro.medium.com/max/532/1*AQKRJsRdWx2HZ85H1yWoKw.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oFsqFovnRPh"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 6. Creating a train and test set\r\n",
        "\r\n",
        "When creating a train and test set on which a machine translator model can be trained and evaluated, a couple of things should thought of throughoutly:\r\n",
        "\r\n",
        "- The vocabularies of both the source and target language should be mappable to the embedding layers, having the semantic meaning of the word\r\n",
        "- The lenght of sentences vary accross sentences to translate\r\n",
        "- The word in a sequence at t + 1, is the target value of the word in a sequence at t\r\n",
        "- Data sets are often too large to entirely fit into memory, therefore it is often preferred to generate data batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hk0eJW7AqAix"
      },
      "source": [
        "from itertools import chain\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "# creating vocabulary mappings\r\n",
        "all_source_words = sorted(list(set(chain(*[x.split() for x in df.source]))))\r\n",
        "all_target_words = sorted(list(set(chain(*[x.split() for x in df.target]))))\r\n",
        "\r\n",
        "# creating a word to index mapping for source and target\r\n",
        "source_word2idx = {x: i for i, x in enumerate(all_source_words)}\r\n",
        "target_word2idx = {x: i for i, x in enumerate(all_target_words)}\r\n",
        "\r\n",
        "# creating an index to word mapping for source and target vocabulary\r\n",
        "source_idx2word = {value: key for key, value in source_word2idx.items()}\r\n",
        "target_idx2word = {value: key for key, value in target_word2idx.items()}\r\n",
        "\r\n",
        "# determine the maximum length of sentences in the source and target data\r\n",
        "max_source_length = max([len(x.split()) for x in df.source])\r\n",
        "max_target_length = max([len(x.split()) for x in df.target])\r\n",
        "\r\n",
        "\r\n",
        "# define a generate batch function yielding input data to both the encoder and decoder and the target sentences mapped to its vocabulary features (decoded)\r\n",
        "def generate_batch(X: np.ndarray, y: np.ndarray, max_source_length: int, max_target_length: int, num_decoder_tokens: int, batch_size=128):\r\n",
        "  \"\"\"\r\n",
        "  Generating batches of data\r\n",
        "  \"\"\"\r\n",
        "  while True:\r\n",
        "    # loop over input samples to generate samples of size batch size \r\n",
        "    for j in range(0, len(X), batch_size):\r\n",
        "      # initialize encoder input, decoder input and decoded target data\r\n",
        "      encoder_input_data = np.zeros((batch_size, max_source_length), dtype='float32')\r\n",
        "      decoder_input_data = np.zeros((batch_size, max_target_length), dtype='float32')\r\n",
        "      decoder_target_data = np.zeros((batch_size, max_target_length, num_decoder_tokens), dtype='float32')\r\n",
        "\r\n",
        "      # convert input and output sentences to structure which can be trained by LSTM\r\n",
        "      X_batch = X[j:j + batch_size]\r\n",
        "      y_batch = y[j:j + batch_size]\r\n",
        "      for i, (input_text, target_text) in enumerate(zip(X_batch, y_batch)):\r\n",
        "        # map each word of the source sentence to its vocabulary integer\r\n",
        "        for t, word in enumerate(input_text.split()):\r\n",
        "          encoder_input_data[i, t] = source_word2idx[word] \r\n",
        "\r\n",
        "        # map each word of the target sentence to its vocabulary integer\r\n",
        "        for t, word in enumerate(target_text.split()):\r\n",
        "          # exclude the last token in target sentence (i.e. _END) as this token should not be input for a next word in the sequence\r\n",
        "          if t < len(target_text.split()) - 1: \r\n",
        "              decoder_input_data[i, t] = target_word2idx[word]\r\n",
        "          \r\n",
        "          # add boolean array of true next words in the sequence (i.e. a word in the sequence at t + 1 is the target value of the word in a sequence at t)\r\n",
        "          # offset by 1 time step\r\n",
        "          if t>0:\r\n",
        "              decoder_target_data[i, t - 1, target_word2idx[word]] = 1.\r\n",
        "      \r\n",
        "      # yield batch data\r\n",
        "      yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCX1WmaMyi0j"
      },
      "source": [
        "The data set is splitted into a train and test set, before these are fed into the generate batch function. Moreover, the data is shuffeled which helps the model to be more robust. For your knowledge, the original dataset is sorted on sentence length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4p2ZY8Z_z3nL"
      },
      "source": [
        "from sklearn.utils import shuffle\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "# shuffle the data\r\n",
        "df = shuffle(df)\r\n",
        "\r\n",
        "# create training and test data set\r\n",
        "X, y = df.source, df.target\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size=0.1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISWqX90N0tLD"
      },
      "source": [
        "---\r\n",
        "--- \r\n",
        "# 7. Building the sequence-to-sequence model\r\n",
        "\r\n",
        "Recall that we need to create an encoder and decoder LSTM network. \r\n",
        "\r\n",
        "Moreover, we will be training our own embedding layers to capture the necessary meanings of the input and output words.\r\n",
        "\r\n",
        "Next to that, we will be using the method 'Teacher Forcing' to train the sequence-to-sequence model. Teacher Forcing works by using the actual or expected output from the training data set at the current time step y(t) as input in the next time step X(t+1), rather than the output generated by the network. \r\n",
        "\r\n",
        "- Embedding dimension = 100\r\n",
        "- Latent dimension = 256 (i.e. dimension of context vectors c and h)\r\n",
        "- Number of encoder tokens = lenght of source vocabulary (i.e. used in embedding layer)\r\n",
        "- Number of decoder tokens = length of target vocabulary + 1 (i.e. as we zero pad for non existing words in a sequence of length max target sequence)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cq6LXnL5HLP"
      },
      "source": [
        "# set some parameters for the encoder and decoder\r\n",
        "embedding_dim = 100\r\n",
        "latent_dim = 256\r\n",
        "num_encoder_tokens = len(all_source_words)\r\n",
        "num_decoder_tokens = len(all_target_words) + 1  # zero pad"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5EkeS0x2fq8"
      },
      "source": [
        "### Encoder\r\n",
        "\r\n",
        "The encoder will encode the input sequence into a context vector, consisting of the working memory and its long-term memory.\r\n",
        "1. Input sequence goes into input layer\r\n",
        "2. Input layer connects to embedding layer (this maps the input to a 3D array of shape (batch samples, max sentence length, word features)\r\n",
        "3. The embedding layer connects to the LSTM layer(s)\r\n",
        "\r\n",
        "We are particulary interested in the context of this encoder, which is achieved by setting return_state=True and discarding the final outputs of the LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTah78ee4zuk"
      },
      "source": [
        "from keras.layers import Input, LSTM, Embedding\r\n",
        "\r\n",
        "\r\n",
        "# 1. input sequence goes into input layer\r\n",
        "encoder_inputs = Input(shape=(None,))\r\n",
        "\r\n",
        "# 2. input layer connects to embedding layer\r\n",
        "# mask_zero is set True which implies that the input value of 0 is a special padding value that should be masked out\r\n",
        "enc_emb = Embedding(num_encoder_tokens, embedding_dim, mask_zero=True)(encoder_inputs)\r\n",
        "\r\n",
        "# 3. Connect embedding layer to LSTM layer\r\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\r\n",
        "final_enc_outputs, state_h, state_c = encoder_lstm(enc_emb)\r\n",
        "\r\n",
        "# discard the final encoder outputs and only keep the states (used as input for LSTM layer in decoder)\r\n",
        "encoder_context = [state_h, state_c]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI4AY5ig9I49"
      },
      "source": [
        "### Decoder\r\n",
        "\r\n",
        "The decoder will decode the context vector into an output sequence, item by item.\r\n",
        "\r\n",
        "1. Output sequence goes into input layer (i.e. remember it is a sequential process)\r\n",
        "2. Input layer is again connected to embedding layer\r\n",
        "3. LSTM layer in the decoder takes the input of the embedding layer and the context of the encoder as its input\r\n",
        "4. Add a dense layer including a softmax activation to map the output of the decoder to a word in the target vocabulary\r\n",
        "\r\n",
        "In case of the decoder, we want to return the output of the LSTM layers in between time steps, as well as the internal working memory (h(i) )and long-term memory states (c(i)). These internal states, c(i) and h(i), are not used during training, but will be used during the inference phase.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbLYSoq8BMdm"
      },
      "source": [
        "from keras.layers import Dense\r\n",
        "\r\n",
        "\r\n",
        "# 1. output sequence goes into input layer Set up the decoder, using `encoder_states` as initial state.\r\n",
        "decoder_inputs = Input(shape=(None,))\r\n",
        "\r\n",
        "# 2. input layer is connected to embedding layer\r\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, embedding_dim, mask_zero=True)\r\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\r\n",
        "\r\n",
        "# 3. LSTM layer takes input of embedding layer and the context of the encoder\r\n",
        "# return sequence is set True as we are interested in the output prections for all time steps\r\n",
        "# internal states (h and c) are not used during training\r\n",
        "# LSTM layer is initialized with the context vector of the encoder\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=encoder_context)\r\n",
        "\r\n",
        "# 4. adding a dense layer incl. softmax activation such that mapping to target vocabulary can be done\r\n",
        "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\r\n",
        "decoder_outputs = decoder_dense(decoder_outputs)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz9WZQhcCoSe"
      },
      "source": [
        "The total sequence to sequence model takes both encoder and decoder inputs and predicts decoder outputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHT9GWTJC-7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5325a11c-dc37-4391-bd37-7c62f47653f1"
      },
      "source": [
        "from keras.models import Model\r\n",
        "\r\n",
        "# the model that takes encoder and decoder input to output decoder outputs\r\n",
        "train_model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\r\n",
        "\r\n",
        "# print summary\r\n",
        "train_model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 100)    868400      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    1231400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 256), (None, 365568      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  365568      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 12314)  3164698     lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 5,995,634\n",
            "Trainable params: 5,995,634\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuZESGxCDZs-"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 8. Training the sequence-to-sequence model\r\n",
        "\r\n",
        "To train the model, in keras, we first compile the model and then fit the data (using batches) to the model. To fit the model using batches of input data, we use the fit_generator() method. \r\n",
        "\r\n",
        "More specifically, we use the following settings:\r\n",
        "- optimizer: RMSPROP\r\n",
        "- loss function: categorical crossentropy, as we use categorical labels (one-hot encoded vectors for each target word)\r\n",
        "- metrics: accuracy\r\n",
        "- batch size: 128\r\n",
        "- epochs: 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrs_nxfDDaEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2b22a9b-8d29-494f-f429-8a6207f0c480"
      },
      "source": [
        "# parameters\r\n",
        "train_samples = len(X_train) # total training samples\r\n",
        "val_samples = len(X_test)    # total validation or test samples\r\n",
        "batch_size = 128\r\n",
        "epochs = 30\r\n",
        "optimizer = 'rmsprop'\r\n",
        "loss = 'categorical_crossentropy'\r\n",
        "metrics = ['acc']\r\n",
        "\r\n",
        "# compiling the model\r\n",
        "train_model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\r\n",
        "\r\n",
        "# define batch generator for train and validation purposes\r\n",
        "train_gen = generate_batch(X_train, y_train, max_source_length=max_source_length, max_target_length=max_target_length, num_decoder_tokens=num_decoder_tokens, batch_size=batch_size)\r\n",
        "test_gen = generate_batch(X_test, y_test, max_source_length=max_source_length, max_target_length=max_target_length, num_decoder_tokens=num_decoder_tokens, batch_size=batch_size)\r\n",
        "\r\n",
        "# training the model\r\n",
        "train_model.fit_generator(generator=train_gen,\r\n",
        "                          steps_per_epoch=train_samples//batch_size,\r\n",
        "                          epochs=epochs,\r\n",
        "                          validation_data=test_gen,\r\n",
        "                          validation_steps=val_samples//batch_size)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "370/370 [==============================] - 176s 456ms/step - loss: 0.7629 - acc: 0.1898 - val_loss: 0.6551 - val_acc: 0.2342\n",
            "Epoch 2/30\n",
            "370/370 [==============================] - 166s 449ms/step - loss: 0.6215 - acc: 0.2475 - val_loss: 0.5838 - val_acc: 0.2840\n",
            "Epoch 3/30\n",
            "370/370 [==============================] - 166s 449ms/step - loss: 0.5550 - acc: 0.3004 - val_loss: 0.5341 - val_acc: 0.3393\n",
            "Epoch 4/30\n",
            "370/370 [==============================] - 165s 447ms/step - loss: 0.5033 - acc: 0.3518 - val_loss: 0.4951 - val_acc: 0.3792\n",
            "Epoch 5/30\n",
            "370/370 [==============================] - 165s 446ms/step - loss: 0.4609 - acc: 0.3959 - val_loss: 0.4612 - val_acc: 0.4181\n",
            "Epoch 6/30\n",
            "370/370 [==============================] - 166s 448ms/step - loss: 0.4238 - acc: 0.4342 - val_loss: 0.4352 - val_acc: 0.4476\n",
            "Epoch 7/30\n",
            "370/370 [==============================] - 165s 446ms/step - loss: 0.3934 - acc: 0.4672 - val_loss: 0.4180 - val_acc: 0.4705\n",
            "Epoch 8/30\n",
            "370/370 [==============================] - 166s 448ms/step - loss: 0.3664 - acc: 0.4975 - val_loss: 0.4008 - val_acc: 0.4894\n",
            "Epoch 9/30\n",
            "370/370 [==============================] - 166s 449ms/step - loss: 0.3433 - acc: 0.5245 - val_loss: 0.3870 - val_acc: 0.5056\n",
            "Epoch 10/30\n",
            "370/370 [==============================] - 165s 445ms/step - loss: 0.3230 - acc: 0.5490 - val_loss: 0.3762 - val_acc: 0.5199\n",
            "Epoch 11/30\n",
            "370/370 [==============================] - 166s 448ms/step - loss: 0.3048 - acc: 0.5721 - val_loss: 0.3677 - val_acc: 0.5311\n",
            "Epoch 12/30\n",
            "370/370 [==============================] - 165s 445ms/step - loss: 0.2872 - acc: 0.5946 - val_loss: 0.3612 - val_acc: 0.5410\n",
            "Epoch 13/30\n",
            "370/370 [==============================] - 165s 447ms/step - loss: 0.2722 - acc: 0.6146 - val_loss: 0.3551 - val_acc: 0.5500\n",
            "Epoch 14/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.2588 - acc: 0.6324 - val_loss: 0.3518 - val_acc: 0.5585\n",
            "Epoch 15/30\n",
            "370/370 [==============================] - 165s 446ms/step - loss: 0.2468 - acc: 0.6489 - val_loss: 0.3482 - val_acc: 0.5604\n",
            "Epoch 16/30\n",
            "370/370 [==============================] - 164s 443ms/step - loss: 0.2354 - acc: 0.6640 - val_loss: 0.3455 - val_acc: 0.5639\n",
            "Epoch 17/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.2246 - acc: 0.6786 - val_loss: 0.3423 - val_acc: 0.5671\n",
            "Epoch 18/30\n",
            "370/370 [==============================] - 164s 443ms/step - loss: 0.2154 - acc: 0.6922 - val_loss: 0.3412 - val_acc: 0.5707\n",
            "Epoch 19/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.2069 - acc: 0.7045 - val_loss: 0.3399 - val_acc: 0.5723\n",
            "Epoch 20/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.1987 - acc: 0.7167 - val_loss: 0.3390 - val_acc: 0.5728\n",
            "Epoch 21/30\n",
            "370/370 [==============================] - 165s 447ms/step - loss: 0.1906 - acc: 0.7281 - val_loss: 0.3390 - val_acc: 0.5736\n",
            "Epoch 22/30\n",
            "370/370 [==============================] - 165s 446ms/step - loss: 0.1834 - acc: 0.7402 - val_loss: 0.3386 - val_acc: 0.5760\n",
            "Epoch 23/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.1770 - acc: 0.7491 - val_loss: 0.3381 - val_acc: 0.5790\n",
            "Epoch 24/30\n",
            "370/370 [==============================] - 165s 446ms/step - loss: 0.1713 - acc: 0.7586 - val_loss: 0.3390 - val_acc: 0.5790\n",
            "Epoch 25/30\n",
            "370/370 [==============================] - 164s 444ms/step - loss: 0.1646 - acc: 0.7691 - val_loss: 0.3399 - val_acc: 0.5771\n",
            "Epoch 26/30\n",
            "370/370 [==============================] - 164s 443ms/step - loss: 0.1589 - acc: 0.7777 - val_loss: 0.3414 - val_acc: 0.5779\n",
            "Epoch 27/30\n",
            "370/370 [==============================] - 164s 443ms/step - loss: 0.1532 - acc: 0.7861 - val_loss: 0.3416 - val_acc: 0.5796\n",
            "Epoch 28/30\n",
            "370/370 [==============================] - 166s 447ms/step - loss: 0.1483 - acc: 0.7937 - val_loss: 0.3436 - val_acc: 0.5771\n",
            "Epoch 29/30\n",
            "370/370 [==============================] - 166s 448ms/step - loss: 0.1433 - acc: 0.8015 - val_loss: 0.3448 - val_acc: 0.5786\n",
            "Epoch 30/30\n",
            "370/370 [==============================] - 165s 447ms/step - loss: 0.1388 - acc: 0.8078 - val_loss: 0.3445 - val_acc: 0.5812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f35f667f320>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZYZWryHfn3"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 9. Inferencing from the model\r\n",
        "\r\n",
        "During inference we want to translate unknown input sequence to predict the output, and evaluate from there. Batch size equals 1 for simplicity.\r\n",
        "\r\n",
        "1. Encode the input sequences into context vectors (1 context vector for each sample)\r\n",
        "2. Predict the decoded sentence one by one, where the first input to the decoder will the context vector of the encoder and the embedded _START \r\n",
        "3. The output of the decoder will be fed as an input to the decoder for the next time step\r\n",
        "\r\n",
        "  ![inference](https://miro.medium.com/max/554/1*AyyknGa07gMGVLhiWCruNQ.png)\r\n",
        "\r\n",
        "4. Convert the decoded output (one-hot encoded) vector to the word from the target dictionary\r\n",
        "5. Append the generated target word to the target sentence\r\n",
        "6. Repeat the steps till we hit the _END tag or a sentence limit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDQ0QPzfXIMX"
      },
      "source": [
        "### Define the inference model\r\n",
        "\r\n",
        "By defining the inference model, we basically mean, use the trained layers from the trained model, but now also use the working memory (h(i)) and long term memory (c(i)) from the decoder model as input for the next output sequence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W46sIolXuK3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273fba2d-b9e2-4cc9-ec48-d2cbe81e979e"
      },
      "source": [
        "# inference model uses encoder model to convert input sequence to context vectors\r\n",
        "encoder_model = Model(encoder_inputs, encoder_context)\r\n",
        "\r\n",
        "# decoder gets new context output (i.e. h(i), c(i)) from previous time step\r\n",
        "dec_context_input = [Input(shape=(latent_dim, )), Input(shape=(latent_dim, ))]\r\n",
        "\r\n",
        "# decoder gets embedded target word in sequence as input; using trained embedding layer\r\n",
        "dec_emb_inf = dec_emb_layer(decoder_inputs)\r\n",
        "\r\n",
        "# set the lstm initial state to the states from the previous time step; using trained lstm layer\r\n",
        "dec_outputs_inf, state_h_inf, state_c_inf = decoder_lstm(dec_emb_inf, initial_state=dec_context_input)\r\n",
        "dec_context_inf = [state_h_inf, state_c_inf]\r\n",
        "\r\n",
        "# use the trained dense softmax layer to generate vocabulary predictions, using the newly generated context vectors\r\n",
        "dec_outputs_inf = decoder_dense(dec_outputs_inf)\r\n",
        "\r\n",
        "# combine steps in a total inference model; decoder inputs and its context vectors output decoded outputs and decoded context vectors\r\n",
        "decoder_model = Model([decoder_inputs] + dec_context_input, [dec_outputs_inf] + dec_context_inf)\r\n",
        "\r\n",
        "# print model summary\r\n",
        "decoder_model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 100)    1231400     input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 256),  365568      embedding_1[1][0]                \n",
            "                                                                 input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 12314)  3164698     lstm_1[1][0]                     \n",
            "==================================================================================================\n",
            "Total params: 4,761,666\n",
            "Trainable params: 4,761,666\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTUDxzhEdZel"
      },
      "source": [
        "Inference multiple test sequences from the inference model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nniyyJ3V-Sh"
      },
      "source": [
        "output_sentence_limit = 50\r\n",
        "\r\n",
        "\r\n",
        "def inference_from_model(input_seq: np.ndarray, output_sentence_limit=50):\r\n",
        "  \"\"\"\r\n",
        "  Decode a single sentence using the trained model. That is batch_size = 1\r\n",
        "  \"\"\"\r\n",
        "  # 1. encode the input into context vectors\r\n",
        "  states_value = encoder_model.predict(input_seq)\r\n",
        "\r\n",
        "  # 2. start with a target sequence of size 1 (just the start-of-sequence word)\r\n",
        "  target_seq = np.zeros((1,1))\r\n",
        "  target_seq[0, 0] = target_word2idx['START_']\r\n",
        "\r\n",
        "  decoded_sentence = ''\r\n",
        "  while True:\r\n",
        "    # print(f'target_seq: {target_seq}')\r\n",
        "    # 3. feed the state vectors and start word target sequence to the decoder to produce predictions for the next word\r\n",
        "    output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\r\n",
        "\r\n",
        "    # 4. sample the next word using the predictions done by decoder\r\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\r\n",
        "    sampled_word = target_idx2word[sampled_token_index]\r\n",
        "\r\n",
        "    # 5. append the sampled character to the target sequence\r\n",
        "    target_seq[0, 0] = sampled_token_index\r\n",
        "    decoded_sentence += ' ' + sampled_word\r\n",
        "\r\n",
        "    # Update states\r\n",
        "    states_value = [h, c]\r\n",
        "\r\n",
        "    # exit loop if stop condition is met\r\n",
        "    if sampled_word == '_END' or len(decoded_sentence) > output_sentence_limit:\r\n",
        "      break\r\n",
        "    \r\n",
        "  # return sentence\r\n",
        "  return decoded_sentence"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JDiydsqPFasO"
      },
      "source": [
        "#### Inference train set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YOmhDvhFep7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fa28c1a-a560-4bb4-dc4a-e53c77ba300c"
      },
      "source": [
        "# redefine test set generator having batch size one for simplicity\r\n",
        "train_gen = generate_batch(X_train, y_train, max_source_length=max_source_length, max_target_length=max_target_length, num_decoder_tokens=num_decoder_tokens, batch_size=1)\r\n",
        "\r\n",
        "# inference from the model x times\r\n",
        "x = 10\r\n",
        "\r\n",
        "for i, ((input_seq, actual_output), _) in enumerate(train_gen):\r\n",
        "  # inference from model\r\n",
        "  inference_sentence = inference_from_model(input_seq)\r\n",
        "  print(f'Input source sentence: {X_train[i]}')\r\n",
        "  print(f'Actual target translation: {y_train[i]}')\r\n",
        "  print(f'Predicted target translation: {inference_sentence}')\r\n",
        "  print()\r\n",
        "\r\n",
        "  if i >= x:\r\n",
        "    break"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input source sentence: anyone can write his own name\n",
            "Actual target translation: START_ iedereen kan zijn eigen naam schrijven _END\n",
            "Predicted target translation:  een kan ik zijn eigen naam maken _END\n",
            "\n",
            "Input source sentence: the balloon is filled with air\n",
            "Actual target translation: START_ de ballon is gevuld met lucht _END\n",
            "Predicted target translation:  een onder het ligt onder _END\n",
            "\n",
            "Input source sentence: tom doesnt know what mary does for a living\n",
            "Actual target translation: START_ tom weet niet wat mary voor de kost doet _END\n",
            "Predicted target translation:  een weet niet wat tom en mary voor het halen _END\n",
            "\n",
            "Input source sentence: it isnt a secret\n",
            "Actual target translation: START_ het is geen geheim _END\n",
            "Predicted target translation:  een het is niet geheim _END\n",
            "\n",
            "Input source sentence: how long would you say theyve been there tom\n",
            "Actual target translation: START_ hoe lang denk je dat ze daar zijn geweest tom _END\n",
            "Predicted target translation:  een keer denk je denk dat tom daar me zo rij hebben\n",
            "\n",
            "Input source sentence: i want to show you something in my office\n",
            "Actual target translation: START_ ik wil je iets laten zien in mijn kantoor _END\n",
            "Predicted target translation:  een wil ik wil je in het kantoor zien _END\n",
            "\n",
            "Input source sentence: do you play the guitar\n",
            "Actual target translation: START_ spelen jullie gitaar _END\n",
            "Predicted target translation:  een glas je _END\n",
            "\n",
            "Input source sentence: we should save money for a rainy day\n",
            "Actual target translation: START_ we zouden een appeltje tegen de dorst moeten bewaren _END\n",
            "Predicted target translation:  een zouden zouden geld moeten we een land aan het maken\n",
            "\n",
            "Input source sentence: the sea level is rising\n",
            "Actual target translation: START_ het zeeniveau stijgt _END\n",
            "Predicted target translation:  een deur is groter _END\n",
            "\n",
            "Input source sentence: have you seen the news\n",
            "Actual target translation: START_ hebben jullie het nieuws gezien _END\n",
            "Predicted target translation:  een zien jij het goed gezien _END\n",
            "\n",
            "Input source sentence: be sure to look over your paper again before you hand it in\n",
            "Actual target translation: START_ vergeet niet om je papier te herlezen voordat je het inlevert _END\n",
            "Predicted target translation:  een jaar niet goed je moet je dit doet maar in deze\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xnSutBnFU94"
      },
      "source": [
        "#### Inference test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeMXry8HXAz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245299ba-3855-4f8f-8e56-88f05db71a78"
      },
      "source": [
        "# redefine test set generator having batch size one for simplicity\r\n",
        "test_gen = generate_batch(X_test, y_test, max_source_length=max_source_length, max_target_length=max_target_length, num_decoder_tokens=num_decoder_tokens, batch_size=1)\r\n",
        "\r\n",
        "# inference from the model x times\r\n",
        "x = 10\r\n",
        "\r\n",
        "for i, ((input_seq, actual_output), _) in enumerate(test_gen):\r\n",
        "  # inference from model\r\n",
        "  inference_sentence = inference_from_model(input_seq)\r\n",
        "  print(f'Input source sentence: {X_test[i]}')\r\n",
        "  print(f'Actual target translation: {y_test[i]}')\r\n",
        "  print(f'Predicted target translation: {inference_sentence}')\r\n",
        "  print()\r\n",
        "\r\n",
        "  if i >= x:\r\n",
        "    break"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input source sentence: how many books do you read a month\n",
            "Actual target translation: START_ hoeveel boeken lees je per maand _END\n",
            "Predicted target translation:  een boeken heeft u per maand van de engels houdt _END\n",
            "\n",
            "Input source sentence: do you like it when i do this\n",
            "Actual target translation: START_ vind je het leuk als ik dat doe _END\n",
            "Predicted target translation:  een reden hoe je het doen is ik _END\n",
            "\n",
            "Input source sentence: everybody loves him\n",
            "Actual target translation: START_ iedereen houdt van hem _END\n",
            "Predicted target translation:  een kind is gek _END\n",
            "\n",
            "Input source sentence: when i was a child i believed in santa claus\n",
            "Actual target translation: START_ toen ik nog klein was geloofde ik in de kerstman _END\n",
            "Predicted target translation:  een kind was ik hem in de buurt van een autoongeluk\n",
            "\n",
            "Input source sentence: we can win this war\n",
            "Actual target translation: START_ we kunnen deze oorlog winnen _END\n",
            "Predicted target translation:  een kunnen jullie deur nemen _END\n",
            "\n",
            "Input source sentence: i dont see any difference\n",
            "Actual target translation: START_ ik zie geen verschil _END\n",
            "Predicted target translation:  een volgende taal men niet _END\n",
            "\n",
            "Input source sentence: do you think this is fair\n",
            "Actual target translation: START_ vind je dit eerlijk _END\n",
            "Predicted target translation:  een dat dit gaat zeven kind _END\n",
            "\n",
            "Input source sentence: minorities are despised in many countries\n",
            "Actual target translation: START_ minderheden worden in vele landen veracht _END\n",
            "Predicted target translation:  een paar landen in het landen _END\n",
            "\n",
            "Input source sentence: lets hope so\n",
            "Actual target translation: START_ laten we het hopen _END\n",
            "Predicted target translation:  een ons denken dat we er zijn _END\n",
            "\n",
            "Input source sentence: weve got a first aid kit\n",
            "Actual target translation: START_ wij hebben een ehbodoos _END\n",
            "Predicted target translation:  een hebben jullie moeten vertrouwen _END\n",
            "\n",
            "Input source sentence: who does this belong to\n",
            "Actual target translation: START_ van wie is dit _END\n",
            "Predicted target translation:  een doet dit dit gaat tom _END\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUbZPKUSfsI5"
      },
      "source": [
        "---\r\n",
        "---\r\n",
        "# 10. Improvements on current architecture\r\n",
        "\r\n",
        "As you might notice, the results are not quite as estonishing as we would have hoped. Of course this, amongst others, has to do with the limited training capacities. Other possibilities to investigate include:\r\n",
        "\r\n",
        "- Include bi-directional LSTM layers\r\n",
        "\r\n",
        "\r\n",
        "```\r\n",
        "# replace parts in encode\r\n",
        "encoder_lstm = LSTM(latent_dim, return_state=True)\r\n",
        "final_enc_outputs, state_h, state_c = encoder_lstm(enc_emb)\r\n",
        "# by\r\n",
        "encoder_lstm = Bidirectional(LSTM(latent_dim, return_state=True), merge_mode='concat')\r\n",
        "final_enc_outputs, forward_state_h, forward_state_c, backward_state_h, backward_state_c = encoder_lstm(enc_emb)\r\n",
        "state_h = Concatenate()([forward_state_h, backward_state_h])\r\n",
        "state_c = Concatenate()([forward_state_c, backward_state_c])\r\n",
        "\r\n",
        "# replace parts in decoder\r\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\r\n",
        "# by\r\n",
        "decoder_lstm = LSTM(latent_dim*2, return_sequences=True, return_state=True)\r\n",
        "```\r\n",
        "\r\n",
        "\r\n",
        "- Include attention layers\r\n",
        "- Include pre-trained embedded vectors\r\n",
        "\r\n",
        "All of these will be covered in LSTM lecture part 2:) We hope to see you there as well!!\r\n",
        "\r\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kp8LNsPx8WBk"
      },
      "source": [
        ""
      ]
    }
  ]
}